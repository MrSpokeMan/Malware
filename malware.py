# import pandas as pd
# from keras.models import Sequential
# from keras.layers import Dense, Flatten
# from matplotlib import pyplot as plt

# df = pd.read_csv('./header_part.csv', header=None)
# del df[0]
# del df[58]

# print(df.shape)

# model = Sequential()
# model.add(Flatten(input_shape=(4458, 57)))
# model.add(Dense(128, activation='relu'))
# model.add(Dense(256, activation='relu'))
# model.add(Dense(134, activation='softmax'))

# model.summary()

# model.compile(loss='sparse_categorical_crossentropy',
#               optimizer='adam', metrics=['acc'])

# history = model.fit(, validation_data=(), epochs=10)

import pandas as pd
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense, Flatten
from matplotlib import pyplot as plt

# Wczytanie danych z pliku CSV
df = pd.read_csv('./header_part.csv', header=None)
del df[0]
del df[58]

# Podzielenie danych na cechy i etykiety
X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values
y = tf.keras.utils.to_categorical(y, num_classes=134)

# Definicja modelu
model = Sequential([
    Dense(128, activation='relu', input_shape=(X.shape[1],)),
    Dense(256, activation='relu'),
    Dense(134, activation='softmax')
])

# Kompilacja modelu
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Trenowanie modelu
history = model.fit(X, y, epochs=10, batch_size=32)

plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.title('loss')
plt.legend()
plt.figure()

plt.plot(history.history['acc'], label='acc')
plt.plot(history.history['val_acc'], label='val_acc')
plt.title('acc')
plt.legend()

plt.show()
